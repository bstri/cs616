{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "616 Data Collection and Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNhGmFqT_qnx",
        "colab_type": "code",
        "outputId": "61001b96-ea27-4746-be59-17a7a227a0af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyCoET-QAEg9",
        "colab_type": "code",
        "outputId": "c734f83e-e660-4607-d303-f46199f965f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!git clone https://github.com/bstri/cs616"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cs616'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 5 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (5/5), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHVTFDKCITxC",
        "colab_type": "code",
        "outputId": "666045e9-93eb-4b9b-cab6-fd4d8d420357",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#import shutil\n",
        "#shutil.rmtree('eclipse.platform.ui')\n",
        "\n",
        "!git clone https://github.com/eclipse/eclipse.platform.ui\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: import: command not found\n",
            "/bin/bash: -c: line 0: syntax error near unexpected token `'eclipse.platform.ui''\n",
            "/bin/bash: -c: line 0: `shutil.rmtree('eclipse.platform.ui')'\n",
            "Cloning into 'eclipse.platform.ui'...\n",
            "remote: Enumerating objects: 2532, done.\u001b[K\n",
            "remote: Counting objects: 100% (2532/2532), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1288/1288), done.\u001b[K\n",
            "remote: Total 562625 (delta 1061), reused 1754 (delta 584), pack-reused 560093\u001b[K\n",
            "Receiving objects: 100% (562625/562625), 119.59 MiB | 15.80 MiB/s, done.\n",
            "Resolving deltas: 100% (320233/320233), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v7-5_HiJjE6",
        "colab_type": "code",
        "outputId": "9cd602ee-d38c-4317-d143-17f600fe4653",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "!pip install pydriller\n",
        "!pip install ciso8601"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydriller\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/4e/4861d79c6171d43a5facf3e698f5b8beb5b644588f055698a82a45bc0bca/PyDriller-1.14-py3-none-any.whl (62kB)\n",
            "\r\u001b[K     |█████▎                          | 10kB 25.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 40kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 2.4MB/s \n",
            "\u001b[?25hCollecting gitpython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/1a/0df85d2bddbca33665d2148173d3281b290ac054b5f50163ea735740ac7b/GitPython-3.1.1-py3-none-any.whl (450kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 8.2MB/s \n",
            "\u001b[?25hCollecting lizard\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/2c/d6f6a5507cfa685535731428ee3b32b4d7648a5b8c10b68b85de3cdbb649/lizard-1.17.3-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from pydriller) (2018.9)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/52/ca35448b56c53a079d3ffe18b1978c6e424f6d4df02404877094c89f5bfb/gitdb-4.0.4-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.2MB/s \n",
            "\u001b[?25hCollecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/27/b1/e379cfb7c07bbf8faee29c4a1a2469dbea525f047c2b454c4afdefa20a30/smmap-3.0.2-py2.py3-none-any.whl\n",
            "Installing collected packages: smmap, gitdb, gitpython, lizard, pydriller\n",
            "Successfully installed gitdb-4.0.4 gitpython-3.1.1 lizard-1.17.3 pydriller-1.14 smmap-3.0.2\n",
            "Collecting ciso8601\n",
            "  Downloading https://files.pythonhosted.org/packages/2c/da/626910cf8aca7ed2d5b34355eee8aeaaeb6ddd4e16f98d00a9e2ddad3a08/ciso8601-2.1.3.tar.gz\n",
            "Building wheels for collected packages: ciso8601\n",
            "  Building wheel for ciso8601 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ciso8601: filename=ciso8601-2.1.3-cp36-cp36m-linux_x86_64.whl size=28299 sha256=7dc0e956c7eed7140a76bf23627d7557a9d1d62dd3218015922e4b50a4929a3a\n",
            "  Stored in directory: /root/.cache/pip/wheels/eb/32/e4/13bdaf7e245f82667b21e0cfb03d21224691a47fa9f9bc80a6\n",
            "Successfully built ciso8601\n",
            "Installing collected packages: ciso8601\n",
            "Successfully installed ciso8601-2.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoatztJlpxfs",
        "colab_type": "text"
      },
      "source": [
        "Import and parse bug report info into Pandas DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvpufEY2Zunf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "#import xml.etree.ElementTree as ET\n",
        "\n",
        "# This is a one-liner for the record books\n",
        "# brdf = pd.DataFrame([{c.get('name'): ' '.join((c.text or '').split()) for c in el} for el in ET.parse('eclipseBugReports.xml').getroot()[1]])\n",
        "\n",
        "brdf = pd.read_csv('cs616/updated_brdf.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG_faelvLR4F",
        "colab_type": "code",
        "outputId": "91f68f26-9c3b-4c17-de58-46369ff031b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "brdf.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>bug_id</th>\n",
              "      <th>report_timestamp</th>\n",
              "      <th>commit_timestamp</th>\n",
              "      <th>previous_commit_timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6495.000000</td>\n",
              "      <td>6495.000000</td>\n",
              "      <td>6.495000e+03</td>\n",
              "      <td>6.495000e+03</td>\n",
              "      <td>6.495000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3248.000000</td>\n",
              "      <td>177200.583526</td>\n",
              "      <td>1.170273e+09</td>\n",
              "      <td>1.178887e+09</td>\n",
              "      <td>1.178849e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1875.089331</td>\n",
              "      <td>117281.544559</td>\n",
              "      <td>9.527768e+07</td>\n",
              "      <td>9.534308e+07</td>\n",
              "      <td>9.531107e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2025.000000</td>\n",
              "      <td>1.002753e+09</td>\n",
              "      <td>1.002824e+09</td>\n",
              "      <td>1.002819e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1624.500000</td>\n",
              "      <td>70998.500000</td>\n",
              "      <td>1.091019e+09</td>\n",
              "      <td>1.103106e+09</td>\n",
              "      <td>1.103099e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3248.000000</td>\n",
              "      <td>165690.000000</td>\n",
              "      <td>1.164287e+09</td>\n",
              "      <td>1.174842e+09</td>\n",
              "      <td>1.174840e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4871.500000</td>\n",
              "      <td>283442.500000</td>\n",
              "      <td>1.247579e+09</td>\n",
              "      <td>1.259523e+09</td>\n",
              "      <td>1.259523e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>6495.000000</td>\n",
              "      <td>424252.000000</td>\n",
              "      <td>1.387282e+09</td>\n",
              "      <td>1.389886e+09</td>\n",
              "      <td>1.389962e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                id         bug_id  ...  commit_timestamp  previous_commit_timestamp\n",
              "count  6495.000000    6495.000000  ...      6.495000e+03               6.495000e+03\n",
              "mean   3248.000000  177200.583526  ...      1.178887e+09               1.178849e+09\n",
              "std    1875.089331  117281.544559  ...      9.534308e+07               9.531107e+07\n",
              "min       1.000000    2025.000000  ...      1.002824e+09               1.002819e+09\n",
              "25%    1624.500000   70998.500000  ...      1.103106e+09               1.103099e+09\n",
              "50%    3248.000000  165690.000000  ...      1.174842e+09               1.174840e+09\n",
              "75%    4871.500000  283442.500000  ...      1.259523e+09               1.259523e+09\n",
              "max    6495.000000  424252.000000  ...      1.389886e+09               1.389962e+09\n",
              "\n",
              "[8 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXGZ4jQoDmSK",
        "colab_type": "text"
      },
      "source": [
        "Initialize eclipse UI repository mining object and eclipse UI repo\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S30d-p4JJoMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pydriller\n",
        "import datetime\n",
        "\n",
        "eclipse_repo_path = \"eclipse.platform.ui\"\n",
        "\n",
        "# Limit included commits to the specified time frame\n",
        "eclipse_repo_mine = \\\n",
        "    pydriller.RepositoryMining(eclipse_repo_path,\n",
        "                               since=datetime.datetime(2001, 10, 10, 0, 0, 0),\n",
        "                               to=datetime.datetime(2014, 1, 17, 23, 59, 59))\n",
        "\n",
        "eclipse_repo = pydriller.GitRepository(eclipse_repo_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdGQ0J47iW4l",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLDx061qDvbp",
        "colab_type": "text"
      },
      "source": [
        "Note: code commented out because we are now reading the modified data\n",
        "from file.\n",
        "\n",
        "Change truncated `commit` hash to full hash, change rounded `commit_timestamp` to full timestamp, and make `report_timestamp` more exact based on `report_time`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fkdye0tOLd5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import ciso8601\n",
        "\n",
        "# Note: Some of these changes may not be strictly necessary, as it turns out\n",
        "# that the functions for listing files as they existed at a commit and\n",
        "# extracting source files will accept a truncated hash. Nevertheless, having\n",
        "# more exact times is useful for finding the commit that was current for each\n",
        "# bug report.\n",
        "\n",
        "# commits_affected = 0\n",
        "# sheet_row = brdf.shape[0] - 1\n",
        "# for c in eclipse_repo_mine.traverse_commits():\n",
        "#     trunc_hash = c.hash[0:7]\n",
        "#     if trunc_hash == brdf.commit[sheet_row][0:7]:\n",
        "#         brdf.commit[sheet_row] = str(c.hash)\n",
        "#         brdf.commit_timestamp[sheet_row] = int(c.author_date.timestamp())\n",
        "\n",
        "        # I learned this method of converting a formatted date string to a\n",
        "        # timestamp from https://stackoverflow.com/a/27523634\n",
        "        # brdf.report_timestamp[sheet_row] = \\\n",
        "        #     int(ciso8601.parse_datetime(brdf.report_time[sheet_row]).timestamp())\n",
        "\n",
        "        # commits_affected += 1\n",
        "        # if (commits_affected == len(brdf.commit.unique())):\n",
        "        #     break\n",
        "        # sheet_row -= 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtTMRz-jzCFW",
        "colab_type": "code",
        "outputId": "212dd7f4-4f89-4f86-cf63-d79f1138c1c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "brdf.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>bug_id</th>\n",
              "      <th>summary</th>\n",
              "      <th>description</th>\n",
              "      <th>report_time</th>\n",
              "      <th>report_timestamp</th>\n",
              "      <th>status</th>\n",
              "      <th>commit</th>\n",
              "      <th>commit_timestamp</th>\n",
              "      <th>previous_commit</th>\n",
              "      <th>previous_commit_timestamp</th>\n",
              "      <th>files</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>384108</td>\n",
              "      <td>Bug 384108 JUnit view icon no longer shows pro...</td>\n",
              "      <td>Build Identifier: Version: Juno Release Build ...</td>\n",
              "      <td>2012-07-03 03:39:25</td>\n",
              "      <td>1341286765</td>\n",
              "      <td>resolved fixed</td>\n",
              "      <td>5da5952ac820ee036bf94b225389c550c9fd6e35</td>\n",
              "      <td>1389711510</td>\n",
              "      <td>837a195cd9d56e9b8bba03fee6f4e80db753b6d1</td>\n",
              "      <td>1389962476</td>\n",
              "      <td>bundles/org.eclipse.e4.ui.workbench/src/org/ec...</td>\n",
              "      <td>123:bundles/org.eclipse.e4.ui.workbench/src/or...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>385394</td>\n",
              "      <td>Bug 385394 Performance issue regarding enabled...</td>\n",
              "      <td>Build Identifier: Version: 4.2.0 Build id: I20...</td>\n",
              "      <td>2012-07-18 07:41:06</td>\n",
              "      <td>1342597266</td>\n",
              "      <td>resolved fixed</td>\n",
              "      <td>8db6c323e9849920d98e722c437a1f531b97cbdd</td>\n",
              "      <td>1389885883</td>\n",
              "      <td>6cc7cccd973320f28579a4446220d708487809b6</td>\n",
              "      <td>1389887401</td>\n",
              "      <td>bundles/org.eclipse.e4.ui.workbench.renderers....</td>\n",
              "      <td>6:bundles/org.eclipse.e4.ui.workbench.renderer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>423588</td>\n",
              "      <td>Bug 423588 [QuickAccess] Quick Access failure,...</td>\n",
              "      <td>I was working in an inner from master. When I ...</td>\n",
              "      <td>2013-12-09 08:48:44</td>\n",
              "      <td>1386578924</td>\n",
              "      <td>resolved fixed</td>\n",
              "      <td>6750d2546700063bebc6a9567132e7c3f2671e3c</td>\n",
              "      <td>1389816531</td>\n",
              "      <td>602d549f4d027720a55a1983150f5610421d4bcd</td>\n",
              "      <td>1389803076</td>\n",
              "      <td>bundles/org.eclipse.ui.workbench/Eclipse UI/or...</td>\n",
              "      <td>81:bundles/org.eclipse.ui.workbench/Eclipse UI...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>420238</td>\n",
              "      <td>Bug 420238 [CSS] Reduce whitespace usage in th...</td>\n",
              "      <td>One of the major complains I hear is that the ...</td>\n",
              "      <td>2013-10-24 04:08:35</td>\n",
              "      <td>1382587715</td>\n",
              "      <td>verified fixed</td>\n",
              "      <td>77108408a6915617564b031709f0596fa7c75394</td>\n",
              "      <td>1389800398</td>\n",
              "      <td>1f2e7c9d79cc5f66076df1daa952acd0bf96e161</td>\n",
              "      <td>1389799698</td>\n",
              "      <td>bundles/org.eclipse.e4.ui.workbench.renderers....</td>\n",
              "      <td>270:bundles/org.eclipse.e4.ui.workbench.render...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>405216</td>\n",
              "      <td>Bug 405216 Widget disposed exception in Progre...</td>\n",
              "      <td>I have a job that sets the IProgressConstants....</td>\n",
              "      <td>2013-04-08 18:21:10</td>\n",
              "      <td>1365445270</td>\n",
              "      <td>resolved fixed</td>\n",
              "      <td>470f2747e7f4f598aa34b2b109a0bd833dbab942</td>\n",
              "      <td>1387385065</td>\n",
              "      <td>828d765394e7a0af8fca85bc324ad0afcde295ad</td>\n",
              "      <td>1389723936</td>\n",
              "      <td>bundles/org.eclipse.ui.workbench/Eclipse UI/or...</td>\n",
              "      <td>1:bundles/org.eclipse.ui.workbench/Eclipse UI/...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                             result\n",
              "0   1  ...  123:bundles/org.eclipse.e4.ui.workbench/src/or...\n",
              "1   2  ...  6:bundles/org.eclipse.e4.ui.workbench.renderer...\n",
              "2   3  ...  81:bundles/org.eclipse.ui.workbench/Eclipse UI...\n",
              "3   4  ...  270:bundles/org.eclipse.e4.ui.workbench.render...\n",
              "4   5  ...  1:bundles/org.eclipse.ui.workbench/Eclipse UI/...\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qojlUlCTpunm",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQdbAWkhHguA",
        "colab_type": "code",
        "outputId": "cf547bf9-4629-4bbe-b57e-4dcb26d0957b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "brdf.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>bug_id</th>\n",
              "      <th>summary</th>\n",
              "      <th>description</th>\n",
              "      <th>report_time</th>\n",
              "      <th>report_timestamp</th>\n",
              "      <th>status</th>\n",
              "      <th>commit</th>\n",
              "      <th>commit_timestamp</th>\n",
              "      <th>previous_commit</th>\n",
              "      <th>previous_commit_timestamp</th>\n",
              "      <th>files</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6490</th>\n",
              "      <td>6491</td>\n",
              "      <td>5721</td>\n",
              "      <td>Bug 5721 Welcome not disabled</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2001-11-09 14:37:38</td>\n",
              "      <td>1005316658</td>\n",
              "      <td>resolved fixed</td>\n",
              "      <td>16eec34d596d51bb250532ce730c2c12f568c93d</td>\n",
              "      <td>1005337452</td>\n",
              "      <td>9fdcf1469f8729111aa07c9cc27124790b6db6f7</td>\n",
              "      <td>1005336876</td>\n",
              "      <td>bundles/org.eclipse.ui/Eclipse UI/org/eclipse/...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6491</th>\n",
              "      <td>6492</td>\n",
              "      <td>2694</td>\n",
              "      <td>Bug 2694 Editor Selection Dialog: UI suggestio...</td>\n",
              "      <td>MA (09.08.2001 12:04:06) 1. in the preference ...</td>\n",
              "      <td>2001-10-10 22:41:40</td>\n",
              "      <td>1002753700</td>\n",
              "      <td>resolved fixed</td>\n",
              "      <td>74a0be933573348e798737a9b4a2347208d2c421</td>\n",
              "      <td>1003251798</td>\n",
              "      <td>4dd7c7bf8be4f55264f5ece422a1555bcf38ec9c</td>\n",
              "      <td>1003249922</td>\n",
              "      <td>bundles/org.eclipse.ui/Eclipse UI/org/eclipse/...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6492</th>\n",
              "      <td>6493</td>\n",
              "      <td>2682</td>\n",
              "      <td>Bug 2682 [UI] EC: Can't contribute submenu ite...</td>\n",
              "      <td>EC post \"Menus and submenus\" by GB on Aug 2, 2...</td>\n",
              "      <td>2001-10-10 22:41:23</td>\n",
              "      <td>1002753683</td>\n",
              "      <td>resolved fixed</td>\n",
              "      <td>cec14bf0fc360f8a4877a16e446414a897c1cd22</td>\n",
              "      <td>1003162748</td>\n",
              "      <td>7f3eada09c69c9ad37d91cfcf08941d35b58d2f9</td>\n",
              "      <td>1002918537</td>\n",
              "      <td>bundles/org.eclipse.ui/Eclipse JFace/org/eclip...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6493</th>\n",
              "      <td>6494</td>\n",
              "      <td>2558</td>\n",
              "      <td>Bug 2558 [UI] Unzoom can cause view to move ta...</td>\n",
              "      <td>- Open the resource perspective and reset it -...</td>\n",
              "      <td>2001-10-10 22:38:45</td>\n",
              "      <td>1002753525</td>\n",
              "      <td>resolved fixed</td>\n",
              "      <td>254977b62342d954bc5ea92895d7867a27f266df</td>\n",
              "      <td>1002917813</td>\n",
              "      <td>d2517d30726892c9b4795d44148d134c162e82eb</td>\n",
              "      <td>1002913558</td>\n",
              "      <td>bundles/org.eclipse.ui/Eclipse UI/org/eclipse/...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6494</th>\n",
              "      <td>6495</td>\n",
              "      <td>2318</td>\n",
              "      <td>Bug 2318 [UI] Type Hierarchy View resize (1GEN...</td>\n",
              "      <td>jkca (6/1/2001 5:44:46 PM) jre-sdk 116 To dupl...</td>\n",
              "      <td>2001-10-10 22:33:57</td>\n",
              "      <td>1002753237</td>\n",
              "      <td>resolved fixed</td>\n",
              "      <td>8fe046d61ffe811705f28871ea56ed7bb69415e9</td>\n",
              "      <td>1002824440</td>\n",
              "      <td>4953e3e2db29253276e54381f4535c8c245bba20</td>\n",
              "      <td>1002819197</td>\n",
              "      <td>bundles/org.eclipse.ui/Eclipse UI/org/eclipse/...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  bug_id  ...                                              files result\n",
              "6490  6491    5721  ...  bundles/org.eclipse.ui/Eclipse UI/org/eclipse/...    NaN\n",
              "6491  6492    2694  ...  bundles/org.eclipse.ui/Eclipse UI/org/eclipse/...    NaN\n",
              "6492  6493    2682  ...  bundles/org.eclipse.ui/Eclipse JFace/org/eclip...    NaN\n",
              "6493  6494    2558  ...  bundles/org.eclipse.ui/Eclipse UI/org/eclipse/...    NaN\n",
              "6494  6495    2318  ...  bundles/org.eclipse.ui/Eclipse UI/org/eclipse/...    NaN\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6qdfbx8iyKZ",
        "colab_type": "text"
      },
      "source": [
        "Note: code commented out because we are now reading the modified data from file.\n",
        "\n",
        "Update brdf with hashes and timestamps of the commits that were current at the time of each bug report, and the hashes and timestamps of the commit preceding each bug fix commit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XmurJDB7Hvr2",
        "colab": {}
      },
      "source": [
        "# import dateutil\n",
        "\n",
        "# commits_at_reports       = pd.Series([], dtype=\"string\")\n",
        "# commits_at_reports_times = pd.Series([], dtype=\"int\")\n",
        "\n",
        "\n",
        "# Get the commit that was current at the time of each bug report and add its\n",
        "# hash and timestamp to brdf.\n",
        "# for i, rt in enumerate(brdf['report_timestamp']):\n",
        "#     c = None\n",
        "#     rtdt = datetime.datetime.fromtimestamp(rt)\n",
        "\n",
        "#     e_repo_mine_small = \\\n",
        "#         pydriller.RepositoryMining(eclipse_repo_path,\n",
        "#                                    since=datetime.datetime(2001, 10, 10, 0, 0,\n",
        "#                                                            0),\n",
        "#                                    to=rtdt, order='reverse')\n",
        "\n",
        "    # Since we have specified \"order='reverse'\", the first commit traversed is\n",
        "    # usually the one immediately prior to the bug report, unless they were\n",
        "    # submitted at nearly the exact same time. However we still check to ensure\n",
        "    # that the chosen commit was before the bug report.\n",
        "    # for c in e_repo_mine_small.traverse_commits():\n",
        "    #     if datetime.datetime.fromtimestamp(c.author_date.timestamp()) < rtdt:\n",
        "    #         commits_at_reports[i]       = str(c.hash)\n",
        "    #         commits_at_reports_times[i] = int(c.author_date.timestamp())\n",
        "    #         break\n",
        "    #     else:\n",
        "            # Debugging\n",
        "#             print(f'Commit \"{c.hash}\" ({c.author_date.timestamp()}) not before '\n",
        "#                   f'bug report at index {i} ({rt}).')\n",
        "\n",
        "# brdf.insert(6, 'commit_at_report', commits_at_reports)\n",
        "# brdf.insert(7, 'commit_at_report_timestamp', commits_at_reports_times)\n",
        "\n",
        "\n",
        "# prev_commits       = pd.Series([], dtype=\"string\")\n",
        "# prev_commits_times = pd.Series([], dtype=\"int\")\n",
        "\n",
        "# Get the commit that immediately preceded the bug fix commit and add its hash\n",
        "# and timestamp to brdf.\n",
        "# for i, commit_hash in enumerate(brdf['commit']):\n",
        "    # Modified from the checkout command included in the original project\n",
        "    # README.pdf.\n",
        "    # SO answers https://stackoverflow.com/a/41716996,\n",
        "    # https://stackoverflow.com/a/19812608, and\n",
        "    # https://stackoverflow.com/a/1828259 were helpful for getting the\n",
        "    # formatting right.\n",
        "#     prev_commit_hash, prev_commit_ts = \\\n",
        "#         eclipse_repo.git.execute(['git', 'show', '--pretty=format:\"%H %ct',\n",
        "#                                   '--quiet', f'{commit_hash}~1']).split()\n",
        "#     prev_commit_hash      = prev_commit_hash.lstrip('\"')\n",
        "#     prev_commit_ts        = int(prev_commit_ts)\n",
        "#     prev_commits[i]       = prev_commit_hash\n",
        "#     prev_commits_times[i] = prev_commit_ts\n",
        "\n",
        "# brdf.insert(9, 'previous_commit', prev_commits)\n",
        "# brdf.insert(10, 'previous_commit_timestamp', prev_commits_times)\n",
        "\n",
        "# brdf.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpsPK3qnNUVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving to csv so we have the option of simply reading the updated data from\n",
        "# file.\n",
        "# brdf.to_csv('updated_brdf.csv', encoding='utf8', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lex4fFgaD0TG",
        "colab_type": "text"
      },
      "source": [
        "Define function to collect source code from repo given file name and commit, a function that will list the entire file tree at a particular commit, and a function that will return all source code a commit's file tree."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWTvLxMKDziK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import git\n",
        "import pathlib\n",
        "\n",
        "recent_commit = 'a84b0f91988cc76f11094b507cdb4832a41502db'\n",
        "\n",
        "def extractSrc(filepath, commit_hash):\n",
        "    # Returns the text of `filepath` in `commit_hash` as a string\n",
        "    src = None\n",
        "    try:\n",
        "        src = eclipse_repo.git.show(f'{commit_hash}:{filepath}')\n",
        "    except git.GitCommandError:\n",
        "        print('err')\n",
        "        pass\n",
        "    return src\n",
        "\n",
        "\n",
        "def ls_commit(commit_hash):\n",
        "    # List all source files in commit. Trying with reset because show was too\n",
        "    # slow and inaccurate.\n",
        "    tree = None\n",
        "    eclipse_repo.git.reset('--hard', commit_hash)\n",
        "    eclipse_repo.git.clean('-xdf')\n",
        "    ecp = pathlib.Path(eclipse_repo_path)\n",
        "    tree = [str(fp) for fp in ecp.rglob('*') if fp.suffix == '.java'\n",
        "            and not fp.name.startswith('.')]\n",
        "    # switch back\n",
        "    eclipse_repo.git.reset('--hard', recent_commit)\n",
        "    eclipse_repo.git.clean('-xdf')\n",
        "    return tuple(tree)\n",
        "\n",
        "\n",
        "def extract_commit_corpus(commit_hash, file_list=None, return_names=False):\n",
        "    # Returns a tuple of strings, each of which represents one document in the\n",
        "    # repo. If given a file_list, only the files in the file list are returned\n",
        "    corpus  = []\n",
        "    tree = None\n",
        "    eclipse_repo.git.reset('--hard', commit_hash)\n",
        "    eclipse_repo.git.clean('-xdf')\n",
        "    ecp = pathlib.Path(eclipse_repo_path)\n",
        "    # get only java or class files and no hidden files\n",
        "    tree = sorted([str(fp) for fp in ecp.rglob('*') if fp.suffix == '.java'\n",
        "                   and not fp.name.startswith('.')])\n",
        "    if file_list:\n",
        "        mod_tree = sorted([fp for fp in tree if re.sub(f'{eclipse_repo_path}/',\n",
        "                                                       '', fp) in file_list])\n",
        "        tree = mod_tree\n",
        "    for doc in tree:\n",
        "        src = None\n",
        "        # Read only ascii characters, replace others with '?'. This is necessary\n",
        "        # because some files are apparently not unicode.\n",
        "        with open(doc, 'r', encoding='ascii', errors='replace') as f:\n",
        "            src = f.read()\n",
        "        if src is not None:\n",
        "            if return_names:\n",
        "                corpus.append(re.sub(f'{eclipse_repo_path}/', '', doc))\n",
        "            corpus.append(src)\n",
        "    # switch back\n",
        "    eclipse_repo.git.reset('--hard', recent_commit)\n",
        "    eclipse_repo.git.clean('-xdf')\n",
        "    return tuple(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIFXy89CET7R",
        "colab_type": "text"
      },
      "source": [
        "Define functions for preparing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyQ4A21trUrG",
        "colab_type": "code",
        "outputId": "76213a2d-4f74-4a79-8099-a6460e5bc2f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import math\n",
        "import numpy\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import porter, WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "def split_camelcase(word):\n",
        "    if word.isupper() or word.islower():\n",
        "        split_words = [word]\n",
        "    else:\n",
        "        # One liner from https://stackoverflow.com/a/37697078\n",
        "        # Inserts a blank before each capital letter, and then splits the\n",
        "        # resulting string using the blanks.\n",
        "        split_words = re.sub('([A-Z][a-z]+)', r' \\1', re.sub('([A-Z]+)', r' \\1',\n",
        "                                                             word)).split()\n",
        "    return split_words\n",
        "\n",
        "\n",
        "def preprocess(txt):\n",
        "    # Keep only printable ascii letters, replace others with space.\n",
        "    # This range of control characters is modified from\n",
        "    # https://stackoverflow.com/a/39416125. We only have ascii characters so we\n",
        "    # only need exclude non-printable ascii characters, not the full Unicode\n",
        "    # range\n",
        "    non_printable = re.compile(r'[\\x00-\\x1f\\7f]')\n",
        "    printable_txt = re.sub(non_printable, \" \", txt)\n",
        "\n",
        "    # Replace all punctuation with whitespace. The paper only states that they\n",
        "    # removed punctuation, but doing it this way ensures that words separated by\n",
        "    # a period or a parenthesis, for example, will be properly split.\n",
        "    # I learned to use re.escape from https://stackoverflow.com/a/266162\n",
        "    punct = string.punctuation\n",
        "    punct_patt = re.compile('[{punct}]'.format(punct=re.escape(punct)))\n",
        "    no_punct_txt = re.sub(punct_patt, \" \", printable_txt)\n",
        "\n",
        "    # split into bag of words using whitespace\n",
        "    ws = re.compile(r'\\s+')\n",
        "    tokens = re.split(ws, no_punct_txt)\n",
        "\n",
        "\n",
        "    # Remove numbers, except those that are in words with alphabetic characters.\n",
        "    # This is to allow for the possible use of numbers and punctuation (periods,\n",
        "    # underscores) in method, class names, etc. The paper was not clear as to\n",
        "    # whether they removed all numbers or simply those tokens that consisted\n",
        "    # only of numerals. I have taken the latter approach.\n",
        "    digits = string.digits\n",
        "    alpha = string.ascii_letters\n",
        "\n",
        "    # First add only words without any numbers to the new list.\n",
        "    alpha_only_tokens = [t for t in tokens\n",
        "                         if len(set(t).intersection(set(digits))) == 0]\n",
        "\n",
        "    # Add words that contain letters *and* numbers.\n",
        "    alpha_only_tokens.extend([t for t in tokens\n",
        "                              if len(set(t).intersection(set(alpha))) > 0\n",
        "                              and len(set(t).intersection(set(digits))) > 0])\n",
        "\n",
        "    # Remove stop words, that is, words which generally do not add much\n",
        "    # meaning to a sentence like articles and conjunctions.\n",
        "    sw = stopwords.words(\"english\")\n",
        "    tokens = [t for t in alpha_only_tokens if t not in sw]\n",
        "\n",
        "    # Split compound words written in CamelCase into parts based on capital\n",
        "    # letters, and augment our token list with those parts.\n",
        "    for t in tokens:\n",
        "        t_parts = split_camelcase(t)\n",
        "\n",
        "        # Words not in CamelCase will have only one list element: the original\n",
        "        # word. Otherwise, augment our token list with the individual parts.\n",
        "        if len(t_parts) > 1:\n",
        "            for t_part in t_parts:\n",
        "                tokens.append(t_part)\n",
        "\n",
        "    # Get the morphological stem of the word using the Porter stemmer from\n",
        "    # ntlk. We might also consider using lemmatization rather than stemming.\n",
        "    # This is more computationally intensive, and so can take considerably\n",
        "    # longer, but it yields more accurate results. I have included commented\n",
        "    # code using a lemmatizer. The stemmer converts most words to lowercase,\n",
        "    # while the lemmatizer does not, so this is something we might need to\n",
        "    # tweak if we decide to use a lemmatizer.\n",
        "    stemmer = porter.PorterStemmer()\n",
        "    base_tokens = [stemmer.stem(t) for t in tokens]\n",
        "\n",
        "    # Using a lemmatizer\n",
        "    # lemmatizer = WordNetLemmatizer()\n",
        "    # base_tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
        "\n",
        "    # Final check to make sure there are no empty strings\n",
        "    tokens = [t for t in base_tokens if t]\n",
        "\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def build_vocab(txt):\n",
        "    # Create a processed list of unique words from a document\n",
        "    doc_words = preprocess(txt)\n",
        "    vocab = set(doc_words)\n",
        "    return vocab\n",
        "\n",
        "\n",
        "def count_vectorize(corpus, vocab=None):\n",
        "    # Tokenize and vectorize text with simple count frequencies.\n",
        "    vectorizer = CountVectorizer(analyzer=preprocess, vocabulary=vocab)\n",
        "\n",
        "    count_vector = vectorizer.fit_transform(corpus)\n",
        "\n",
        "    count_vector_arr = count_vector.toarray()\n",
        "\n",
        "    return count_vector_arr\n",
        "\n",
        "\n",
        "def tfidf_vectorize_query(query, corpus, vocab=None, return_cv=False):\n",
        "    q_cv_array = count_vectorize([query], vocab=vocab)\n",
        "\n",
        "    q_vector = q_cv_array[0]\n",
        "\n",
        "    # Number of documents in corpus\n",
        "    n = int(corpus.shape[0])\n",
        "\n",
        "    # Number of terms in corpus\n",
        "    tc = len(q_vector)\n",
        "\n",
        "    # Initialize list that will hold file counts for each term with zeroes\n",
        "    files_per_term = [0 for i in range(tc)]\n",
        "\n",
        "    # calculate the number of documents in which each term appears\n",
        "    for row in corpus:\n",
        "        for col_num, cell in enumerate(row):\n",
        "            if cell > 0:\n",
        "                files_per_term[col_num] += 1\n",
        "\n",
        "    # Initialize TD-IDF vector for query\n",
        "    q_tfidf_list = [0.0 for j in range(tc)]\n",
        "\n",
        "    # `a` is the smoothing term. See\n",
        "    # https://nlp.stanford.edu/IR-book/html/htmledition/maximum-tf-normalization-1.html\n",
        "    a = 0.5\n",
        "\n",
        "    max_tf = 0\n",
        "    for tf in q_vector:\n",
        "        if tf > max_tf:\n",
        "            max_tf = tf\n",
        "    for i, tf in enumerate(q_vector):\n",
        "        # We leave the weighted term frequency as 0 if a term does not appear\n",
        "        # in the string.\n",
        "        if tf > 0:\n",
        "            # Calculate normalized term weight according to method used in\n",
        "            # Ye et al.\n",
        "            nf = a + (1.0 - a) * (tf/max_tf)\n",
        "\n",
        "            # Calculate idf. Here we add one to the numerator and\n",
        "            # denominator to prevent the possibility of division by zero. This\n",
        "            # is not mentioned in the paper, but is the method of \"smoothing\"\n",
        "            # used by the sklearn tfidf vectorizer.\n",
        "            idf = math.log10((n + 1)/(files_per_term[i] + 1))\n",
        "\n",
        "            # Calculate adjusted weight and store in TD-IDF vector array\n",
        "            wf = nf * idf\n",
        "            q_tfidf_list[i] = wf\n",
        "\n",
        "    # Convert list to numpy array\n",
        "    q_tfidf_arr = numpy.array(q_tfidf_list)\n",
        "\n",
        "    if return_cv:\n",
        "        return q_tfidf_arr, q_vector\n",
        "    else:\n",
        "        return q_tfidf_arr\n",
        "\n",
        "\n",
        "def tfidf_vectorize_corpus(corpus, vocab=None, return_cv=False,\n",
        "                           count_vector_array=None):\n",
        "    if count_vector_array is None:\n",
        "        cv_array = count_vectorize(corpus, vocab=vocab)\n",
        "    else:\n",
        "        cv_array = count_vector_array\n",
        "\n",
        "    # Initialize number of documents in corpus\n",
        "    n = 0\n",
        "\n",
        "    # Number of terms in corpus\n",
        "    tc = len(cv_array[0])\n",
        "\n",
        "    # Initialize list that will hold file counts for each term with zeroes\n",
        "    files_per_term = [0 for i in range(tc)]\n",
        "\n",
        "    # calculate the number of document in corpus and number of files in which\n",
        "    # each term appears\n",
        "    for row in cv_array:\n",
        "        n += 1\n",
        "        for col_num, cell in enumerate(row):\n",
        "            if cell > 0:\n",
        "                files_per_term[col_num] += 1\n",
        "\n",
        "    # Initialize TD-IDF array with zeroes\n",
        "    tfidf_list = [[0.0 for j in range(tc)] for i in range(n)]\n",
        "\n",
        "    # `a` is the smoothing term. See\n",
        "    # https://nlp.stanford.edu/IR-book/html/htmledition/maximum-tf-normalization-1.html\n",
        "    a = 0.5\n",
        "\n",
        "    for i, row in enumerate(cv_array):\n",
        "        max_tf = 0\n",
        "        for tf in row:\n",
        "            if tf > max_tf:\n",
        "                max_tf = tf\n",
        "        for j, tf in enumerate(row):\n",
        "            # We leave the weighted term frequency as 0 if a term does not\n",
        "            # appear in the string.\n",
        "            if tf > 0:\n",
        "                # Calculate normalized term weight according to method used in\n",
        "                # Ye et al.\n",
        "                nf = a + (1.0 - a) * (tf/max_tf)\n",
        "\n",
        "                # Calculate idf. Here we add one to the numerator and\n",
        "                # denominator to prevent the possibility of division by zero.\n",
        "                # This is not mentioned in the paper, but is the method of\n",
        "                # \"smoothing\" used by the sklearn tfidf vectorizer.\n",
        "                idf = math.log10((n + 1)/(files_per_term[j] + 1))\n",
        "\n",
        "                # Calculate adjusted weight and store in TD-IDF vector array\n",
        "                wf = nf * idf\n",
        "                tfidf_list[i][j] = wf\n",
        "\n",
        "\n",
        "    # Convert array to numpy array\n",
        "    tfidf_arr = numpy.array(tfidf_list)\n",
        "    \n",
        "    if return_cv:\n",
        "        return tfidf_arr, cv_array\n",
        "    else:\n",
        "        return tfidf_arr\n",
        "\n",
        "#mycorpus = ['A green tree', 'A red apple', 'A green apple', 'A red tree']\n",
        "#query = 'Where is the apple tree'\n",
        "#corpus_and_query = mycorpus.copy()\n",
        "#corpus_and_query.append(query)\n",
        "#corpus_and_query_str = '\\n'.join(corpus_and_query)\n",
        "#myvocab = sorted(list(build_vocab(corpus_and_query_str)))\n",
        "#corpus_v = tfidf_vectorize_corpus(mycorpus, vocab=myvocab)\n",
        "#query_v = tfidf_vectorize_query(query, corpus_v, vocab=myvocab)\n",
        "#print(corpus_v)\n",
        "#print(query_v)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWp3S6tk4Oa3",
        "colab_type": "text"
      },
      "source": [
        "Create vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGwVRhYC4S0d",
        "colab_type": "code",
        "outputId": "fac3ca3b-6f6e-4ac8-cc59-294fc2ef3cf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# import pickle\n",
        "\n",
        "# corpora = ''\n",
        "# vocab = set()\n",
        "\n",
        "# # Add each bug report\n",
        "# for i, (bug_report, bug_report_summary) in enumerate(zip(brdf['description'],\n",
        "#                                                          brdf['summary'])):\n",
        "#     if i >= 6244:\n",
        "#         print(f'Adding bug report at index {i}')\n",
        "#         complete_report = '\\n'.join([str(bug_report_summary), str(bug_report)])\n",
        "#         corpora = '\\n\\n'.join([corpora, complete_report])\n",
        "\n",
        "# chunk_vocab = build_vocab(corpora)\n",
        "# vocab = vocab.union(chunk_vocab)\n",
        "# corpora = ''\n",
        "# print(list(vocab)[:100])\n",
        "# print(len(vocab))\n",
        "\n",
        "# unique_commits = []\n",
        "\n",
        "# first_commit_index = int(brdf['id'].max()) - 1\n",
        "\n",
        "# first_commit_src = \\\n",
        "#     extract_commit_corpus(brdf['previous_commit'][first_commit_index])\n",
        "\n",
        "# # Add all files from first prefix commit\n",
        "# print(f'Adding pre-fix commit at index {first_commit_index}.')\n",
        "# corpora = '\\n\\n'.join([corpora, '\\n'.join(first_commit_src)])\n",
        "\n",
        "# prior_commit_index = first_commit_index\n",
        "# commit_processed = 1\n",
        "\n",
        "# # Add changed files from every subsequent commit\n",
        "# for i in reversed(range(first_commit_index)):\n",
        "#     # Thanks to https://stackoverflow.com/a/869914 for an efficient way of\n",
        "#     # looping from high to low.\n",
        "#     if brdf['previous_commit'][i] not in unique_commits:\n",
        "#         print(f'Adding changed files from pre-fix commit at index {i}')\n",
        "#         changed_files = \\\n",
        "#             eclipse_repo.git.diff('--name-only',\n",
        "#                                   brdf['previous_commit'][prior_commit_index],\n",
        "#                                   brdf['previous_commit'][i]).split('\\n')\n",
        "#         cur_commit_src = extract_commit_corpus(brdf['previous_commit'][i],\n",
        "#                                                file_list=changed_files)\n",
        "#         corpora = '\\n\\n'.join([corpora, '\\n'.join(cur_commit_src)])\n",
        "#         if commit_processed % 10 == 0:\n",
        "#             chunk_vocab = build_vocab(corpora)\n",
        "#             vocab = vocab.union(chunk_vocab)\n",
        "#             corpora = ''\n",
        "#             print(list(vocab)[:100])\n",
        "#             print(len(vocab))\n",
        "#         prior_commit_index = i\n",
        "#         unique_commits.append(brdf['previous_commit'][i])\n",
        "#         commit_processed += 1\n",
        "#         if commit_processed > 250:\n",
        "#             break\n",
        "\n",
        "# with open('vocab.pickle', 'wb') as f:\n",
        "#     pickle.dump(vocab, f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adding bug report at index 6244\n",
            "Adding bug report at index 6245\n",
            "Adding bug report at index 6246\n",
            "Adding bug report at index 6247\n",
            "Adding bug report at index 6248\n",
            "Adding bug report at index 6249\n",
            "Adding bug report at index 6250\n",
            "Adding bug report at index 6251\n",
            "Adding bug report at index 6252\n",
            "Adding bug report at index 6253\n",
            "Adding bug report at index 6254\n",
            "Adding bug report at index 6255\n",
            "Adding bug report at index 6256\n",
            "Adding bug report at index 6257\n",
            "Adding bug report at index 6258\n",
            "Adding bug report at index 6259\n",
            "Adding bug report at index 6260\n",
            "Adding bug report at index 6261\n",
            "Adding bug report at index 6262\n",
            "Adding bug report at index 6263\n",
            "Adding bug report at index 6264\n",
            "Adding bug report at index 6265\n",
            "Adding bug report at index 6266\n",
            "Adding bug report at index 6267\n",
            "Adding bug report at index 6268\n",
            "Adding bug report at index 6269\n",
            "Adding bug report at index 6270\n",
            "Adding bug report at index 6271\n",
            "Adding bug report at index 6272\n",
            "Adding bug report at index 6273\n",
            "Adding bug report at index 6274\n",
            "Adding bug report at index 6275\n",
            "Adding bug report at index 6276\n",
            "Adding bug report at index 6277\n",
            "Adding bug report at index 6278\n",
            "Adding bug report at index 6279\n",
            "Adding bug report at index 6280\n",
            "Adding bug report at index 6281\n",
            "Adding bug report at index 6282\n",
            "Adding bug report at index 6283\n",
            "Adding bug report at index 6284\n",
            "Adding bug report at index 6285\n",
            "Adding bug report at index 6286\n",
            "Adding bug report at index 6287\n",
            "Adding bug report at index 6288\n",
            "Adding bug report at index 6289\n",
            "Adding bug report at index 6290\n",
            "Adding bug report at index 6291\n",
            "Adding bug report at index 6292\n",
            "Adding bug report at index 6293\n",
            "Adding bug report at index 6294\n",
            "Adding bug report at index 6295\n",
            "Adding bug report at index 6296\n",
            "Adding bug report at index 6297\n",
            "Adding bug report at index 6298\n",
            "Adding bug report at index 6299\n",
            "Adding bug report at index 6300\n",
            "Adding bug report at index 6301\n",
            "Adding bug report at index 6302\n",
            "Adding bug report at index 6303\n",
            "Adding bug report at index 6304\n",
            "Adding bug report at index 6305\n",
            "Adding bug report at index 6306\n",
            "Adding bug report at index 6307\n",
            "Adding bug report at index 6308\n",
            "Adding bug report at index 6309\n",
            "Adding bug report at index 6310\n",
            "Adding bug report at index 6311\n",
            "Adding bug report at index 6312\n",
            "Adding bug report at index 6313\n",
            "Adding bug report at index 6314\n",
            "Adding bug report at index 6315\n",
            "Adding bug report at index 6316\n",
            "Adding bug report at index 6317\n",
            "Adding bug report at index 6318\n",
            "Adding bug report at index 6319\n",
            "Adding bug report at index 6320\n",
            "Adding bug report at index 6321\n",
            "Adding bug report at index 6322\n",
            "Adding bug report at index 6323\n",
            "Adding bug report at index 6324\n",
            "Adding bug report at index 6325\n",
            "Adding bug report at index 6326\n",
            "Adding bug report at index 6327\n",
            "Adding bug report at index 6328\n",
            "Adding bug report at index 6329\n",
            "Adding bug report at index 6330\n",
            "Adding bug report at index 6331\n",
            "Adding bug report at index 6332\n",
            "Adding bug report at index 6333\n",
            "Adding bug report at index 6334\n",
            "Adding bug report at index 6335\n",
            "Adding bug report at index 6336\n",
            "Adding bug report at index 6337\n",
            "Adding bug report at index 6338\n",
            "Adding bug report at index 6339\n",
            "Adding bug report at index 6340\n",
            "Adding bug report at index 6341\n",
            "Adding bug report at index 6342\n",
            "Adding bug report at index 6343\n",
            "Adding bug report at index 6344\n",
            "Adding bug report at index 6345\n",
            "Adding bug report at index 6346\n",
            "Adding bug report at index 6347\n",
            "Adding bug report at index 6348\n",
            "Adding bug report at index 6349\n",
            "Adding bug report at index 6350\n",
            "Adding bug report at index 6351\n",
            "Adding bug report at index 6352\n",
            "Adding bug report at index 6353\n",
            "Adding bug report at index 6354\n",
            "Adding bug report at index 6355\n",
            "Adding bug report at index 6356\n",
            "Adding bug report at index 6357\n",
            "Adding bug report at index 6358\n",
            "Adding bug report at index 6359\n",
            "Adding bug report at index 6360\n",
            "Adding bug report at index 6361\n",
            "Adding bug report at index 6362\n",
            "Adding bug report at index 6363\n",
            "Adding bug report at index 6364\n",
            "Adding bug report at index 6365\n",
            "Adding bug report at index 6366\n",
            "Adding bug report at index 6367\n",
            "Adding bug report at index 6368\n",
            "Adding bug report at index 6369\n",
            "Adding bug report at index 6370\n",
            "Adding bug report at index 6371\n",
            "Adding bug report at index 6372\n",
            "Adding bug report at index 6373\n",
            "Adding bug report at index 6374\n",
            "Adding bug report at index 6375\n",
            "Adding bug report at index 6376\n",
            "Adding bug report at index 6377\n",
            "Adding bug report at index 6378\n",
            "Adding bug report at index 6379\n",
            "Adding bug report at index 6380\n",
            "Adding bug report at index 6381\n",
            "Adding bug report at index 6382\n",
            "Adding bug report at index 6383\n",
            "Adding bug report at index 6384\n",
            "Adding bug report at index 6385\n",
            "Adding bug report at index 6386\n",
            "Adding bug report at index 6387\n",
            "Adding bug report at index 6388\n",
            "Adding bug report at index 6389\n",
            "Adding bug report at index 6390\n",
            "Adding bug report at index 6391\n",
            "Adding bug report at index 6392\n",
            "Adding bug report at index 6393\n",
            "Adding bug report at index 6394\n",
            "Adding bug report at index 6395\n",
            "Adding bug report at index 6396\n",
            "Adding bug report at index 6397\n",
            "Adding bug report at index 6398\n",
            "Adding bug report at index 6399\n",
            "Adding bug report at index 6400\n",
            "Adding bug report at index 6401\n",
            "Adding bug report at index 6402\n",
            "Adding bug report at index 6403\n",
            "Adding bug report at index 6404\n",
            "Adding bug report at index 6405\n",
            "Adding bug report at index 6406\n",
            "Adding bug report at index 6407\n",
            "Adding bug report at index 6408\n",
            "Adding bug report at index 6409\n",
            "Adding bug report at index 6410\n",
            "Adding bug report at index 6411\n",
            "Adding bug report at index 6412\n",
            "Adding bug report at index 6413\n",
            "Adding bug report at index 6414\n",
            "Adding bug report at index 6415\n",
            "Adding bug report at index 6416\n",
            "Adding bug report at index 6417\n",
            "Adding bug report at index 6418\n",
            "Adding bug report at index 6419\n",
            "Adding bug report at index 6420\n",
            "Adding bug report at index 6421\n",
            "Adding bug report at index 6422\n",
            "Adding bug report at index 6423\n",
            "Adding bug report at index 6424\n",
            "Adding bug report at index 6425\n",
            "Adding bug report at index 6426\n",
            "Adding bug report at index 6427\n",
            "Adding bug report at index 6428\n",
            "Adding bug report at index 6429\n",
            "Adding bug report at index 6430\n",
            "Adding bug report at index 6431\n",
            "Adding bug report at index 6432\n",
            "Adding bug report at index 6433\n",
            "Adding bug report at index 6434\n",
            "Adding bug report at index 6435\n",
            "Adding bug report at index 6436\n",
            "Adding bug report at index 6437\n",
            "Adding bug report at index 6438\n",
            "Adding bug report at index 6439\n",
            "Adding bug report at index 6440\n",
            "Adding bug report at index 6441\n",
            "Adding bug report at index 6442\n",
            "Adding bug report at index 6443\n",
            "Adding bug report at index 6444\n",
            "Adding bug report at index 6445\n",
            "Adding bug report at index 6446\n",
            "Adding bug report at index 6447\n",
            "Adding bug report at index 6448\n",
            "Adding bug report at index 6449\n",
            "Adding bug report at index 6450\n",
            "Adding bug report at index 6451\n",
            "Adding bug report at index 6452\n",
            "Adding bug report at index 6453\n",
            "Adding bug report at index 6454\n",
            "Adding bug report at index 6455\n",
            "Adding bug report at index 6456\n",
            "Adding bug report at index 6457\n",
            "Adding bug report at index 6458\n",
            "Adding bug report at index 6459\n",
            "Adding bug report at index 6460\n",
            "Adding bug report at index 6461\n",
            "Adding bug report at index 6462\n",
            "Adding bug report at index 6463\n",
            "Adding bug report at index 6464\n",
            "Adding bug report at index 6465\n",
            "Adding bug report at index 6466\n",
            "Adding bug report at index 6467\n",
            "Adding bug report at index 6468\n",
            "Adding bug report at index 6469\n",
            "Adding bug report at index 6470\n",
            "Adding bug report at index 6471\n",
            "Adding bug report at index 6472\n",
            "Adding bug report at index 6473\n",
            "Adding bug report at index 6474\n",
            "Adding bug report at index 6475\n",
            "Adding bug report at index 6476\n",
            "Adding bug report at index 6477\n",
            "Adding bug report at index 6478\n",
            "Adding bug report at index 6479\n",
            "Adding bug report at index 6480\n",
            "Adding bug report at index 6481\n",
            "Adding bug report at index 6482\n",
            "Adding bug report at index 6483\n",
            "Adding bug report at index 6484\n",
            "Adding bug report at index 6485\n",
            "Adding bug report at index 6486\n",
            "Adding bug report at index 6487\n",
            "Adding bug report at index 6488\n",
            "Adding bug report at index 6489\n",
            "Adding bug report at index 6490\n",
            "Adding bug report at index 6491\n",
            "Adding bug report at index 6492\n",
            "Adding bug report at index 6493\n",
            "Adding bug report at index 6494\n",
            "['coreexcept', 'pagesit', 'tri', 'edg', 'runasyncmessag', 'progressmonitorpart', 'problemat', 'windowclos', 'iedcontain', 'relaunch', 'address', 'xalanrt', 'proc', 'gradiant', 'stop', 'ed', 'step', 'task', 'NE', 'seterrormessag', 'substr', 'even', 'pleas', 'statement', 'createcont', 'alloc', 'actoractionfactori', 'dont', 'file', 'johntest', 'debug', 'brought', 'tabl', 'openpr', 'tabletre', 'invalid', 'advis', 'enter', '1ge8h7o', 'debuguiplugin', 'P2', 'decoratormanag', 'getfram', 'soon', 'OS', 'getstr', 'inconsist', 'dialogpagecontextcomput', 'gone', 'stacktrac', 'draw2d', 'sourcecon', 'igurationel', 'rightmost', 'noti', 'separ', 'syncexec', 'fieldeditor', 'plat', 'wmnoti', 'erencesact', 'pd', 'callwindowproc', 'runnablelock', 'bottom', '1sec', 'nl', 'near', 'TM', 'dtdmodel', 'editormanag', 'relabel', 'erencepag', 'parttabfold', 'typic', 'An', 'hot', 'ew', 'reader', 'gda', 'propertysheetentri', 'addit', 'v2', 'proj', 'y', 'ipersistableel', 'super', 'test2', 'els', 'trigger', 'drawgradi', 'everyon', 'studi', 'tableview', 'setvalu', 'usabl', 'utf', 'introduc', 'guid', 'region']\n",
            "2543\n",
            "Adding pre-fix commit at index 6494.\n",
            "Adding changed files from pre-fix commit at index 6493\n",
            "Adding changed files from pre-fix commit at index 6492\n",
            "Adding changed files from pre-fix commit at index 6491\n",
            "Adding changed files from pre-fix commit at index 6490\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-142471f5aeac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m                                   brdf['previous_commit'][i]).split('\\n')\n\u001b[1;32m     42\u001b[0m         cur_commit_src = extract_commit_corpus(brdf['previous_commit'][i],\n\u001b[0;32m---> 43\u001b[0;31m                                                file_list=changed_files)\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mcorpora\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorpora\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_commit_src\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcommit_processed\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-cbc6b414973b>\u001b[0m in \u001b[0;36mextract_commit_corpus\u001b[0;34m(commit_hash, file_list, return_names)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# switch back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0meclipse_repo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--hard'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecent_commit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0meclipse_repo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-xdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/git/cmd.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mLazyMixin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_persistent_git_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/git/cmd.py\u001b[0m in \u001b[0;36m_call_process\u001b[0;34m(self, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1003\u001b[0m         \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mexec_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_parse_object_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader_line\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/git/cmd.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, command, istream, with_extended_output, with_exceptions, as_process, output_stream, stdout_as_string, kill_after_timeout, with_stdout, universal_newlines, shell, env, max_chunk_size, **subprocess_kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mkill_after_timeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m                     \u001b[0mwatchdog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m                 \u001b[0mstdout_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mkill_after_timeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m                     \u001b[0mwatchdog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communication_started\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   1532\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutExpired\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1535\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeHR5coczeOU",
        "colab_type": "code",
        "outputId": "463fec36-f18a-45fe-b5d8-641d54f31cc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'commit 4953e3e2db29253276e54381f4535c8c245bba20\\nAuthor: Nick Edgar <nick>\\nDate:   Thu Oct 11 16:53:17 2001 +0000\\n\\n    Text input for build 204\\n\\ncommit beda4e71ad1fb1ed72a5b44da73212cb3b290594\\nAuthor: '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3hA4pFycqj_",
        "colab_type": "code",
        "outputId": "2cdaa32a-a432-49ff-acf1-13538a630af6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open('cs616/vocab1.pickle', 'rb') as f:\n",
        "    vocab = pickle.load(f)\n",
        "\n",
        "global_vocab = sorted(list(vocab))\n",
        "\n",
        "len(global_vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15824"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c787b56c-8928-4381-c8a3-d3beea6359bb",
        "id": "zXqHqFtDJu3s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def vectorize_prefix_commit(commit_index, vocab, prior_commit_data=None):\n",
        "    # vectorizes a pre-fix commit with associated bug report\n",
        "    commit_hash = brdf['previous_commit'][commit_index]\n",
        "\n",
        "    if not prior_commit_data:\n",
        "        commit_corpus = \\\n",
        "            extract_commit_corpus(commit_hash, return_names=True)\n",
        "    else:\n",
        "        # Learned about '--name-status' from\n",
        "        # https://stackoverflow.com/a/30050755\n",
        "        changed_files = \\\n",
        "            eclipse_repo.git.diff('--name-status', prior_commit_data[0],\n",
        "                                  commit_hash).split('\\n')\n",
        "\n",
        "        deleted_files = [f.lstrip('D\\t') for f in changed_files\n",
        "                         if f.startswith('D\\t') and f.endswith('.java') and not\n",
        "                         str(pathlib.Path(f).name).startswith('.')]\n",
        "        added_files = [f.lstrip('A\\t') for f in changed_files\n",
        "                       if f.startswith('A\\t') and f.endswith('.java') and not\n",
        "                       str(pathlib.Path(f).name).startswith('.')]\n",
        "        modified_files = [f.lstrip('M\\t') for f in changed_files\n",
        "                          if f.startswith('M\\t') and f.endswith('java') and not\n",
        "                          str(pathlib.Path(f).name).startswith('.')]\n",
        "\n",
        "        if added_files or deleted_files:\n",
        "            # retrieve all, set prior data to none\n",
        "            prior_commit_data = None\n",
        "            commit_corpus = \\\n",
        "                extract_commit_corpus(commit_hash, return_names=True)\n",
        "        else:\n",
        "            # only retrieve modified\n",
        "            commit_corpus = extract_commit_corpus(commit_hash,\n",
        "                                                  file_list=modified_files,\n",
        "                                                  return_names=True)\n",
        "\n",
        "    corpus_filelist = commit_corpus[0::2]\n",
        "    corpus_filecontents = commit_corpus[1::2]\n",
        "\n",
        "    if prior_commit_data:\n",
        "        corpus_filedict = \\\n",
        "            {fp:fc for (fp, fc) in zip(corpus_filelist, corpus_filecontents)}\n",
        "\n",
        "        unmodified_files = list()\n",
        "        unmodified_filecontents = list()\n",
        "        unmodified_count_vectors = list()\n",
        "        added_filecontents = list()\n",
        "        modified_filecontents = list()\n",
        "\n",
        "        for file_data in prior_commit_data[1]:\n",
        "            if file_data[0] == 'bug_report':\n",
        "                continue\n",
        "            if file_data[0] not in deleted_files:\n",
        "                if file_data[0] not in modified_files:\n",
        "                    unmodified_files.append(file_data[0])\n",
        "                    unmodified_count_vectors.append(file_data[2])\n",
        "                    unmodified_filecontents.append(file_data[3])\n",
        "                else:\n",
        "                    modified_filecontents.append(corpus_filedict[file_data[0]])\n",
        "\n",
        "        for filepath in added_files:\n",
        "            added_filecontents.append(corpus_filedict[file_data[0]])\n",
        "\n",
        "        new_count_vectors = count_vectorize([*modified_files, *added_files],\n",
        "                                            vocab=vocab)\n",
        "        count_vectors = numpy.array([*unmodified_count_vectors,\n",
        "                                     *new_count_vectors])\n",
        "        vect_corpus_arg = None\n",
        "        corpus_filelist = [*unmodified_files, *modified_files, *added_files]\n",
        "        corpus_filecontents = [*unmodified_filecontents,\n",
        "                               *modified_filecontents, *added_filecontents]\n",
        "    else:\n",
        "        count_vectors = None\n",
        "        vect_corpus_arg = corpus_filecontents\n",
        "\n",
        "    # Vectorize pre-fix commit corpus\n",
        "    print(f'Vectorizing pre-fix commit at index {commit_index}.')\n",
        "    if prior_commit_data:\n",
        "        print(len(corpus_filedict))\n",
        "    tfidf_v, count_v = tfidf_vectorize_corpus(vect_corpus_arg,\n",
        "                                              vocab=vocab,\n",
        "                                              return_cv=True,\n",
        "                                              count_vector_array=count_vectors)\n",
        "\n",
        "    complete_query = '\\n'.join([str(brdf['summary'][commit_index]),\n",
        "                                str(brdf['description'][commit_index])])\n",
        "    q_tfidf_v, q_count_v = tfidf_vectorize_query(complete_query,\n",
        "                                                 corpus=tfidf_v,\n",
        "                                                 vocab=vocab,\n",
        "                                                 return_cv=True)\n",
        "\n",
        "    corpus_data = list()\n",
        "    corpus_data.append(('bug_report', q_tfidf_v, q_count_v, complete_query))\n",
        "\n",
        "    for filepath, cv, tfidfv, cont in zip(corpus_filelist, tfidf_v, count_v,\n",
        "                                          corpus_filecontents):\n",
        "        corpus_data.append((filepath, cv, tfidfv, cont))\n",
        "\n",
        "    return tuple((commit_hash, tuple(corpus_data)))\n",
        "\n",
        "\n",
        "# first_commit_data = vectorize_prefix_commit(6494, vocab=global_vocab)\n",
        "# second_commit_data = \\\n",
        "#     vectorize_prefix_commit(6493, vocab=global_vocab,\n",
        "#                             prior_commit_data=first_commit_data)\n",
        "# third_commit_data = \\\n",
        "#     vectorize_prefix_commit(6492, vocab=global_vocab,\n",
        "#                             prior_commit_data=second_commit_data)\n",
        "\n",
        "# content_differs_1_2 = 0\n",
        "# cv_differs_1_2 = 0\n",
        "# content_differs_2_3 = 0\n",
        "# cv_differs_2_3 = 0\n",
        "\n",
        "# for f1 in first_commit_data[1]:\n",
        "#     for f2 in second_commit_data[1]:\n",
        "#         if f1[0] == f2[0]:\n",
        "#             if f1[0] != 'bug_report':\n",
        "#                 if f1[3] != f2[3]:\n",
        "#                     content_differs_1_2 += 1\n",
        "#                 if not (f1[2] == f2[2]).all():\n",
        "#                     cv_differs_1_2 += 1\n",
        "#             break\n",
        "\n",
        "# print(content_differs_1_2)\n",
        "# print(cv_differs_1_2)\n",
        "\n",
        "# for f1 in second_commit_data[1]:\n",
        "#     for f2 in third_commit_data[1]:\n",
        "#         if f1[0] == f2[0]:\n",
        "#             if f1[0] != 'bug_report':\n",
        "#                 if f1[3] != f2[3]:\n",
        "#                     content_differs_2_3 += 1\n",
        "#                 if not (f1[2] == f2[2]).all():\n",
        "#                     cv_differs_2_3 += 1\n",
        "#             break\n",
        "\n",
        "# print(content_differs_2_3)\n",
        "# print(cv_differs_2_3)\n",
        "\n",
        "unique_commits = []\n",
        "\n",
        "# first_commit_index = brdf.shape[0] - 1\n",
        "# cur_commit_data = vectorize_prefix_commit(first_commit_index,\n",
        "#                                           vocab=global_vocab)\n",
        "# cur_commit_hash = brdf['previous_commit'][first_commit_index]\n",
        "\n",
        "# with open(f'gdrive/My Drive/Colab Files/{first_commit_index}.pickle', 'wb') as f:\n",
        "#     pickle.dump(cur_commit_data, f)\n",
        "\n",
        "# unique_commits.append(cur_commit_hash)\n",
        "previous_commit_data = None\n",
        "commits_processed = 0\n",
        "\n",
        "# Loop over the next oldest 249 commits\n",
        "#for i in reversed(range(first_commit_index)):\n",
        "for i in reversed(range(6362)):\n",
        "    cur_commit_hash = brdf['previous_commit'][i]\n",
        "    if cur_commit_hash not in unique_commits:\n",
        "        # Thanks to https://stackoverflow.com/a/869914 for an efficient way of\n",
        "        # looping from high to low.\n",
        "        cur_commit_data = \\\n",
        "            vectorize_prefix_commit(i, vocab=global_vocab,\n",
        "                                    prior_commit_data=previous_commit_data)\n",
        "\n",
        "        with open(f'gdrive/My Drive/Colab Files/{i}.pickle', 'wb') as f:\n",
        "            pickle.dump(cur_commit_data, f)\n",
        "\n",
        "        unique_commits.append(cur_commit_hash)\n",
        "        previous_commit_data = cur_commit_data\n",
        "        commits_processed += 1\n",
        "\n",
        "        if commits_processed == 117:\n",
        "            break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectorizing pre-fix commit at index 6361.\n",
            "Vectorizing pre-fix commit at index 6360.\n",
            "7\n",
            "Vectorizing pre-fix commit at index 6359.\n",
            "3\n",
            "Vectorizing pre-fix commit at index 6358.\n",
            "1\n",
            "Vectorizing pre-fix commit at index 6357.\n",
            "12\n",
            "Vectorizing pre-fix commit at index 6356.\n",
            "1\n",
            "Vectorizing pre-fix commit at index 6355.\n",
            "1\n",
            "Vectorizing pre-fix commit at index 6354.\n",
            "4\n",
            "Vectorizing pre-fix commit at index 6353.\n",
            "1\n",
            "Vectorizing pre-fix commit at index 6352.\n",
            "4\n",
            "Vectorizing pre-fix commit at index 6351.\n",
            "2\n",
            "Vectorizing pre-fix commit at index 6350.\n",
            "2\n",
            "Vectorizing pre-fix commit at index 6349.\n",
            "6\n",
            "Vectorizing pre-fix commit at index 6348.\n",
            "3\n",
            "Vectorizing pre-fix commit at index 6347.\n",
            "4\n",
            "Vectorizing pre-fix commit at index 6346.\n",
            "1\n",
            "Vectorizing pre-fix commit at index 6345.\n",
            "Vectorizing pre-fix commit at index 6344.\n",
            "2\n",
            "Vectorizing pre-fix commit at index 6343.\n",
            "1\n",
            "Vectorizing pre-fix commit at index 6342.\n",
            "8\n",
            "Vectorizing pre-fix commit at index 6341.\n",
            "1\n",
            "Vectorizing pre-fix commit at index 6340.\n",
            "10\n",
            "Vectorizing pre-fix commit at index 6339.\n",
            "6\n",
            "Vectorizing pre-fix commit at index 6338.\n",
            "15\n",
            "Vectorizing pre-fix commit at index 6337.\n",
            "Vectorizing pre-fix commit at index 6336.\n",
            "24\n",
            "Vectorizing pre-fix commit at index 6335.\n",
            "Vectorizing pre-fix commit at index 6334.\n",
            "11\n",
            "Vectorizing pre-fix commit at index 6333.\n",
            "Vectorizing pre-fix commit at index 6332.\n",
            "Vectorizing pre-fix commit at index 6331.\n",
            "1\n",
            "Vectorizing pre-fix commit at index 6330.\n",
            "Vectorizing pre-fix commit at index 6329.\n",
            "Vectorizing pre-fix commit at index 6328.\n",
            "Vectorizing pre-fix commit at index 6327.\n",
            "Vectorizing pre-fix commit at index 6326.\n",
            "Vectorizing pre-fix commit at index 6325.\n",
            "1\n",
            "Vectorizing pre-fix commit at index 6324.\n",
            "5\n",
            "Vectorizing pre-fix commit at index 6323.\n",
            "Vectorizing pre-fix commit at index 6322.\n",
            "1\n",
            "Vectorizing pre-fix commit at index 6321.\n",
            "Vectorizing pre-fix commit at index 6320.\n",
            "95\n",
            "Vectorizing pre-fix commit at index 6319.\n",
            "Vectorizing pre-fix commit at index 6318.\n",
            "2\n",
            "Vectorizing pre-fix commit at index 6317.\n",
            "Vectorizing pre-fix commit at index 6316.\n",
            "Vectorizing pre-fix commit at index 6315.\n",
            "7\n",
            "Vectorizing pre-fix commit at index 6314.\n",
            "6\n",
            "Vectorizing pre-fix commit at index 6313.\n",
            "9\n",
            "Vectorizing pre-fix commit at index 6312.\n",
            "7\n",
            "Vectorizing pre-fix commit at index 6311.\n",
            "1\n",
            "Vectorizing pre-fix commit at index 6310.\n",
            "Vectorizing pre-fix commit at index 6309.\n",
            "3\n",
            "Vectorizing pre-fix commit at index 6308.\n",
            "1\n",
            "Vectorizing pre-fix commit at index 6307.\n",
            "7\n",
            "Vectorizing pre-fix commit at index 6306.\n",
            "1\n",
            "Vectorizing pre-fix commit at index 6305.\n",
            "13\n",
            "Vectorizing pre-fix commit at index 6304.\n",
            "2\n",
            "Vectorizing pre-fix commit at index 6303.\n",
            "9\n",
            "Vectorizing pre-fix commit at index 6302.\n",
            "1\n",
            "Vectorizing pre-fix commit at index 6301.\n",
            "Vectorizing pre-fix commit at index 6300.\n",
            "17\n",
            "Vectorizing pre-fix commit at index 6299.\n",
            "Vectorizing pre-fix commit at index 6298.\n",
            "Vectorizing pre-fix commit at index 6297.\n",
            "1\n",
            "Vectorizing pre-fix commit at index 6296.\n",
            "Vectorizing pre-fix commit at index 6295.\n",
            "9\n",
            "Vectorizing pre-fix commit at index 6294.\n",
            "Vectorizing pre-fix commit at index 6293.\n",
            "1\n",
            "Vectorizing pre-fix commit at index 6292.\n",
            "22\n",
            "Vectorizing pre-fix commit at index 6291.\n",
            "Vectorizing pre-fix commit at index 6290.\n",
            "Vectorizing pre-fix commit at index 6289.\n",
            "7\n",
            "Vectorizing pre-fix commit at index 6288.\n",
            "1\n",
            "Vectorizing pre-fix commit at index 6287.\n",
            "7\n",
            "Vectorizing pre-fix commit at index 6286.\n",
            "7\n",
            "Vectorizing pre-fix commit at index 6285.\n",
            "Vectorizing pre-fix commit at index 6284.\n",
            "17\n",
            "Vectorizing pre-fix commit at index 6283.\n",
            "1\n",
            "Vectorizing pre-fix commit at index 6282.\n",
            "Vectorizing pre-fix commit at index 6281.\n",
            "Vectorizing pre-fix commit at index 6280.\n",
            "Vectorizing pre-fix commit at index 6279.\n",
            "10\n",
            "Vectorizing pre-fix commit at index 6278.\n",
            "Vectorizing pre-fix commit at index 6277.\n",
            "4\n",
            "Vectorizing pre-fix commit at index 6276.\n",
            "1\n",
            "Vectorizing pre-fix commit at index 6275.\n",
            "3\n",
            "Vectorizing pre-fix commit at index 6274.\n",
            "5\n",
            "Vectorizing pre-fix commit at index 6273.\n",
            "Vectorizing pre-fix commit at index 6272.\n",
            "Vectorizing pre-fix commit at index 6271.\n",
            "9\n",
            "Vectorizing pre-fix commit at index 6270.\n",
            "3\n",
            "Vectorizing pre-fix commit at index 6269.\n",
            "4\n",
            "Vectorizing pre-fix commit at index 6268.\n",
            "1\n",
            "Vectorizing pre-fix commit at index 6267.\n",
            "Vectorizing pre-fix commit at index 6266.\n",
            "2\n",
            "Vectorizing pre-fix commit at index 6265.\n",
            "Vectorizing pre-fix commit at index 6264.\n",
            "8\n",
            "Vectorizing pre-fix commit at index 6263.\n",
            "Vectorizing pre-fix commit at index 6262.\n",
            "1\n",
            "Vectorizing pre-fix commit at index 6261.\n",
            "Vectorizing pre-fix commit at index 6260.\n",
            "5\n",
            "Vectorizing pre-fix commit at index 6259.\n",
            "14\n",
            "Vectorizing pre-fix commit at index 6258.\n",
            "12\n",
            "Vectorizing pre-fix commit at index 6257.\n",
            "1\n",
            "Vectorizing pre-fix commit at index 6256.\n",
            "Vectorizing pre-fix commit at index 6255.\n",
            "1\n",
            "Vectorizing pre-fix commit at index 6254.\n",
            "Vectorizing pre-fix commit at index 6253.\n",
            "Vectorizing pre-fix commit at index 6252.\n",
            "1\n",
            "Vectorizing pre-fix commit at index 6251.\n",
            "9\n",
            "Vectorizing pre-fix commit at index 6250.\n",
            "1\n",
            "Vectorizing pre-fix commit at index 6249.\n",
            "4\n",
            "Vectorizing pre-fix commit at index 6248.\n",
            "7\n",
            "Vectorizing pre-fix commit at index 6247.\n",
            "Vectorizing pre-fix commit at index 6246.\n",
            "2\n",
            "Vectorizing pre-fix commit at index 6245.\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glKlifBMEq5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}